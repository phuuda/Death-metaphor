{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import statistics\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "file_path = \"/Users/Sofia/Desktop/LING_506/project/data/cancer_research_coping_with_loss.csv\"\n",
    "#file_path = \"/Users/Sofia/Desktop/LING_506/project/data/cancer_research_dying_with_cancer.csv\"\n",
    "#file_path = \"/Users/Sofia/Desktop/LING_506/project/data/cancer_research_living_with_cancer.csv\"\n",
    "#file_path = \"/Users/Sofia/Desktop/LING_506/project/data/cancer_research_caring.csv\"\n",
    "\n",
    "coping_loss_data = pd.read_csv(file_path, delimiter=\"\\t\")\n",
    "column_names = ['Thread_name', 'Thread_address', 'Username', \"Post_id\",\n",
    "                                  \"Date\", \"Post_text\", \"Reply_to_id\"]\n",
    "\n",
    "#result = coping_loss_data.tail(10)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4245 total number of threads\n",
      "21122 total number of posts\n",
      "5696 total number of users \n",
      "\n",
      "1365 max num of posts per thread\n",
      "1 min num of posts per thread\n",
      "4.975736160188457 average num of posts per thread\n",
      "2 mode of num of posts per thread \n",
      "\n",
      "1026 max num of posts per user\n",
      "1 min num of posts per user\n",
      "3.7082162921348316 average num of posts per user\n",
      "1 mode of num of posts per user \n",
      "\n",
      "594 max num of threads per user\n",
      "1 min num of threads per user\n",
      "2.259129213483146 average num of threads per user\n",
      "1 mode of num of threads per user \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DESCRIPTIVE STATISTICS\n",
    "\n",
    "# TOTAL NUMBER OF THREADS:  \n",
    "print(len(coping_loss_data.Thread_name.unique()), \"total number of threads\")\n",
    "\n",
    "# TOTAL NUMBER OF POSTS: \n",
    "print(len(coping_loss_data), \"total number of posts\")\n",
    "\n",
    "# TOTAL NUMBER OF USERS\n",
    "print(len(coping_loss_data.Username.unique()), \"total number of users\", \"\\n\")\n",
    "\n",
    "#user_arr = list(coping_loss_data[\"Username\"])\n",
    "#unique_users = set(user_arr)\n",
    "#for user in unique_users:\n",
    "#    print(user)\n",
    "\n",
    "\n",
    "# MAX, MIN, AVERAGE NUM OF POSTS PER THREAD ----------------------------------\n",
    "\n",
    "thread_arr = list(coping_loss_data[\"Thread_name\"])\n",
    "thread_post_count = Counter(thread_arr) # count how many times each thread has a post\n",
    "thread_post_count = dict(sorted(thread_post_count.items(), key=lambda item: item[1]))\n",
    "\n",
    "#for thread, post_count in thread_post_count.items():\n",
    "#    print(thread, post_count)\n",
    "\n",
    "num_posts_thread = list(thread_post_count.values())\n",
    "\n",
    "print(max(num_posts_thread), \"max num of posts per thread\")\n",
    "print(min(num_posts_thread), \"min num of posts per thread\")\n",
    "print(statistics.mean(num_posts_thread), \"average num of posts per thread\")\n",
    "print(statistics.mode(num_posts_thread), \"mode of num of posts per thread\", \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# MAX, MIN, AVERAGE NUM OF POSTS PER USER ----------------------------------\n",
    "\n",
    "# count how many times user appears in rows\n",
    "user_arr = list(coping_loss_data[\"Username\"])\n",
    "user_post_count = Counter(user_arr) # count how many times each user has a post\n",
    "user_post_count = dict(sorted(user_post_count.items(), key=lambda item: item[1]))\n",
    "\n",
    "#for user, post_count in user_post_count.items():\n",
    "#    print(user, post_count)\n",
    "\n",
    "num_user_posts_thread = list(user_post_count.values())\n",
    "\n",
    "print(max(num_user_posts_thread), \"max num of posts per user\")\n",
    "print(min(num_user_posts_thread), \"min num of posts per user\")\n",
    "print(statistics.mean(num_user_posts_thread), \"average num of posts per user\")\n",
    "print(statistics.mode(num_user_posts_thread), \"mode of num of posts per user\", \"\\n\")\n",
    "\n",
    "\n",
    "# MAX, MIN, AVERAGE NUM OF THREADS PER USER ----------------------------------\n",
    "\n",
    "user_arr = list(coping_loss_data[\"Username\"]) # list of users\n",
    "thread_arr = list(coping_loss_data[\"Thread_name\"]) # list of threads\n",
    "user_set = list(set(user_arr)) # list of unique users\n",
    "\n",
    "user_thread_dict = dict() #key: user, value: list of unique threads where they posted\n",
    "\n",
    "for i in range(len(user_arr)):\n",
    "\n",
    "    if user_arr[i] in user_thread_dict.keys(): # check for user key\n",
    "        if thread_arr[i] not in user_thread_dict[user_arr[i]]: # check if thread is in user's value list\n",
    "            user_thread_dict[user_arr[i]].append(thread_arr[i])\n",
    "    else:\n",
    "        user_thread_dict[user_arr[i]] = [thread_arr[i]]\n",
    "        \n",
    "#for user, threads in user_thread_dict.items():\n",
    "#    print(user, threads)\n",
    "\n",
    "\n",
    "user_num_thread_dict = dict() #key: user, value: num of unique threads where they posted\n",
    "\n",
    "for user in user_arr:\n",
    "    user_num_thread_dict[user] = len(user_thread_dict[user])\n",
    "\n",
    "user_num_thread_dict = dict(sorted(user_num_thread_dict.items(), key=lambda item: item[1]))\n",
    "    \n",
    "#for user, threads in user_num_thread_dict.items():\n",
    "#    print(user, threads)\n",
    "\n",
    "num_user_threads_thread = list(user_num_thread_dict.values())\n",
    "\n",
    "print(max(num_user_threads_thread), \"max num of threads per user\")\n",
    "print(min(num_user_threads_thread), \"min num of threads per user\")\n",
    "print(statistics.mean(num_user_threads_thread), \"average num of threads per user\")\n",
    "print(statistics.mode(num_user_threads_thread), \"mode of num of threads per user\", \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 earliest post - year\n",
      "2021 latest post - year\n",
      "2019 year with most posts \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EARLIEST, LATEST FORUM POST \n",
    "\n",
    "date_arr = list(coping_loss_data[\"Date\"]) # list of dates\n",
    "\n",
    "date_arr = sorted(date_arr)\n",
    "\n",
    "years = []\n",
    "\n",
    "for date in date_arr:\n",
    "    date_split = date.split(\" \")\n",
    "    year = date_split[2]\n",
    "    years.append(year)\n",
    "    \n",
    "\n",
    "test_date = date_arr[0]\n",
    "test_date_split = test_date.split(\" \")\n",
    "#print(test_date_split)\n",
    "\n",
    "years = sorted(years)\n",
    "\n",
    "#for year in years:\n",
    "#    print(year)\n",
    "\n",
    "print(min(years), \"earliest post - year\")\n",
    "print(max(years), \"latest post - year\")\n",
    "print(statistics.mode(years), \"year with most posts\", \"\\n\")\n",
    "\n",
    "\n",
    "# DISTRIBUTION OF POSTS BY YEAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text post stats - num of sentences / post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 max num of sentences per post\n",
      "0 min num of sentences per post\n",
      "6.385624319333302 average num of sentences per post\n",
      "1 mode of num of sentences per post \n",
      "\n",
      "854 max num of words per sentence\n",
      "0 min num of words per sentence\n",
      "22.721203043200997 average num of words per sentence\n",
      "11 mode of num of words per sentence \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_posts = list(coping_loss_data[\"Post_text\"])\n",
    "test_text = text_posts[0]\n",
    "\n",
    "# POST LENGTH - NUM OF SENTENCES - MAX, MIN, AVERAGE\n",
    "tokenized_text = sent_tokenize(test_text)\n",
    "\n",
    "# \".....\" not recognized as sentence boundary\n",
    "\n",
    "sent_num_arr = []\n",
    "sent_length_arr = [] # count length of each sentence in words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # remove punctuation\n",
    "\n",
    "count = 0\n",
    "for text in text_posts:\n",
    "    \n",
    "    #print(count)\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        text_sent = sent_tokenize(text) # list of sentences\n",
    "        \n",
    "        for sentence in text_sent:\n",
    "            sent_to_word = tokenizer.tokenize(sentence) # tokenize sentence into words\n",
    "            sent_length_arr.append(len(sent_to_word))\n",
    "            \n",
    "        \n",
    "        sent_num_arr.append(len(text_sent))\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "print(max(sent_num_arr), \"max num of sentences per post\")\n",
    "print(min(sent_num_arr), \"min num of sentences per post\")\n",
    "print(statistics.mean(sent_num_arr), \"average num of sentences per post\")\n",
    "print(statistics.mode(sent_num_arr), \"mode of num of sentences per post\", \"\\n\")\n",
    "\n",
    "# SENTENCE LENGTH NUM OF WORDS - max, min, average\n",
    "\n",
    "print(max(sent_length_arr), \"max num of words per sentence\")\n",
    "print(min(sent_length_arr), \"min num of words per sentence\")\n",
    "print(statistics.mean(sent_length_arr), \"average num of words per sentence\")\n",
    "print(statistics.mode(sent_length_arr), \"mode of num of words per sentence\", \"\\n\")\n",
    "\n",
    "\n",
    "#print(len(tokenized_text))\n",
    "#for sent in tokenized_text:\n",
    "#    print(sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text post stats - num of words / post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3153 max num of words per post\n",
      "0 min num of words per post\n",
      "145.08906671717412 average num of words per post\n",
      "[(76, 122)] mode num of words per post \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POST LENGTH - NUM OF WORDS - MAX, MIN, AVERAGE\n",
    "tokenized_word = word_tokenize(test_text)\n",
    "\n",
    "corpus_all_words = []\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # remove punctuation\n",
    "tokenized_word = tokenizer.tokenize(test_text)\n",
    "\n",
    "#print(len(tokenized_word))\n",
    "#for word in tokenized_word:\n",
    "#    print(word)\n",
    "\n",
    "word_num_arr = []\n",
    "\n",
    "#count = 0\n",
    "for text in text_posts:\n",
    "    \n",
    "    #print(count)\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        text_word_num = tokenizer.tokenize(text)\n",
    "        word_num_arr.append(len(text_word_num))\n",
    "        \n",
    "        corpus_all_words.extend(text_word_num)\n",
    "\n",
    "        #count += 1\n",
    "\n",
    "print(max(word_num_arr), \"max num of words per post\")\n",
    "print(min(word_num_arr), \"min num of words per post\")\n",
    "print(statistics.mean(word_num_arr), \"average num of words per post\")\n",
    "#print(statistics.mode(word_num_arr), \"mode num of words per post\", \"\\n\")\n",
    "\n",
    "mode_counter = Counter(word_num_arr)\n",
    "print(mode_counter.most_common(1), \"mode num of words per post\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text post stats - corpus word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3064136 total words in forum\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_all_words), \"total words in forum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP WORDS (OUTSIDE OF STOP WORDS) - FREQUENCY\n",
    "\n",
    "# remove punctuation, stop words\n",
    "\n",
    "\n",
    "#fdist = FreqDist(tokenized_word)\n",
    "#fdist.most_common(2)\n",
    "\n",
    "\n",
    "\n",
    "# Compare 1st post in thread vs. replies?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
